---
title: Redis常见的面试题
createTime: 2025/08/26 09:22:59
permalink: /bigcompany/kvmajx4g/
---
# Redis 面试题

#### 1. Redis 是什么？

Redis是一个开源的C语言编写、支持网络、可基于内存亦可持久化的日志型、高性能键值对（key-value）的内存数据库，可以用作数据库、缓存、消息中间件等。

- 性能优秀，数据在内存中，读写速度非常快，支持并发10W QPS
  - 读 110000次/s
  - 写 81000次/s
- 丰富的数据类型，支持字符串（strings）、散列（hashes）、列表（lists）、集合（sets）、有序集合（sorted sets）等
- 支持数据持久化。可以将内存中数据保存在磁盘中，重启时加载
- 所有操作都是原子性的，还支持对几个操作合并后的原子性
- 主从复制，哨兵，高可用
- 可以用作分布式锁
- 可以作为消息中间件使用，支持发布订阅

#### 2. Redis 数据类型

| 类型       | 特性                                                         | 应用场景                          |
| ---------- | ------------------------------------------------------------ | --------------------------------- |
| String     | 可以存储任何数据【字符串、整数（取值范围同长整形：64 or 32 位有符号整数）、浮点数、图片、序列化的对象、...】。<br>string类型是二进制安全的，最大能存储512M。<br>支持自增、自减操作。 | ...                               |
| Hash       | 存储键值对的无序散列表，微缩版Redis                          | 存储对象属性                      |
| List       | 双向链表，增删快                                             | 消息队列                          |
| Set        | hash表实现，元素不重复                                       | 利用唯一性，统计访问网站的所有 ip |
| Sorted Set | 与 Set 相比，每个元素增加了一个 score 作为有序映射           | 排行榜                            |

#### 3. Redis 为什么使用单线程，还这么快？

因为 Redis 完全是基于内存的操作，CPU 不是 Redis 的瓶颈，Redis 的瓶颈最有可能是机器内存的大小或者网络带宽。既然单线程容易实现，而且CPU不会成为瓶颈，那就顺理成章的采用单线程的方案了，毕竟采用多线程会有很多麻烦。

Redis 之所以快，是因为；

- Redis完全基于内存，绝大部分请求是纯粹的内存操作，非常迅速，数据存在内存中，类似于HashMap，HashMap的优势就是查找和操作的时间复杂度是O(1)
- 数据结构简单，对数据操作也简单
- 采用单线程，避免了不必要的上下文切换和竞争条件，不存在多线程导致的CPU切换，不用去考虑各种锁的问题，不存在加锁释放锁操作，没有死锁问题导致的性能消耗
- 使用多路复用IO模型(<b>一个线程，通过记录I/O流的状态来同时管理多个I/O，可以提高服务器的吞吐能力</b>)


#### 4. Redis 内存满了怎么办？

> 配置内存大小

```
# redis.conf 配置文件中配置
maxmemory 100mb

# 命令修改
~> config set maxmemory 100mb
```

Redis 定义了几种内存淘汰策略

| 策略                 | 说明                                                         |
| -------------------- | ------------------------------------------------------------ |
| noeviction(默认策略) | 对于写请求不再提供服务，直接返回错误（DEL请求和部分特殊请求除外） |
| allkeys-lru          | 从所有 key 中使用 LRU 算法进行淘汰                           |
| volatile-lru         | 从设置了过期时间的 key 中使用 LRU 算法进行淘汰               |
| allkeys-random       | 从所有 key 中随机淘汰数据                                    |
| volatile-random      | 从设置了过期时间的 key 中随机淘汰                            |
| volatile-ttl         | 在设置了过期时间的 key 中，根据 key 的过期时间进行淘汰，越早过期的优先被淘汰 |

> 设置内存淘汰策略

```
# 修改 redis.conf 文件
maxmemory-policy allkeys-lru

# 命令修改
config get maxmemory-policy
config set max-memory-policy allkeys-lru
```

<font color="#398BDE"><b>扩展——LRU算法</b></font>

> LUR(Least Recently Used): 最近最少使用，是一种缓存置换算法。如果一个数据在最近一段时间没有被用到，那么将来被用到的可能性也很小，就可以被淘汰。
> <br>
> <br>Reids 通过随机采样，每次随机出 5(默认，使用 maxmemory-samples 10修改) 个 key，从里面淘汰掉最近最少使用的 key。

<font color="#398BDE"><b>扩展——LFU算法(Redis4.0)</b></font>

> LFU(Least Frequently Used): 最不常用，根据 key 的最近被访问的频率进行淘汰(即保留热点数据)。

LRU 共有两种策略:

- volatite-lfu

  在设置了过期时间的 key 中使用 LFU 算法淘汰数据

- allkeys-lfu

  在所有 key 中使用 LFU 算法淘汰数据

#### 4. Redis 相对于 Memcache 的优势？

- 支持持久化
- 支持丰富的数据类型


#### 5.Memcached 与 Redis 对比

- 性能
  - 两者性能都比较高

- 数据类型
  - Memcached 数据结构单一
  - Redis 非常丰富

- 内存大小
  - Redis 在 2.0 后增加了自己的 VM 特性，突破物理内存的限制。
  - Memcached 可以修改最大可用内存的大小来管理内存，采用 LRU 算法。

- 持久化
  - Redis 依赖快照、AOF 进行持久化。但 AOF 在增强可靠性的同时，对性能也有所影响。
  - Memcached 不支持持久化、通常用来做缓存，以提升性能。

- value 数据大小
  - Redis 的 value 最大限制是 1GB。
  - Memcached 只能保存 1MB 以内的数据。

- 数据一致性（事务支持）
  - Memcached 在并发场景下用 CAS 保证一致性。
  - Redis 对事务支持比较弱，只能保证事务中的每个操作连续执行。

- 应用场景
  - Reids 适合数据量较少、性能和运算要求高的场景。
  - Memcached 适合提升性能的场景。适合读多写少，如果数据量比较大，则可以采用分片的方式来解决。



#### 6.一个字符串类型的值能存储最大容量是多少？

512MB

#### 7.Redis 的持久化机制是什么？各自的优缺点？

> RDB

- **优点**：

- - （1）`RDB`会生成多个数据文件，每个数据文件都代表了某一个时刻中`redis`的数据，这种多个数据文件的方式，非常适合做**冷备**，可以将这种完整的数据文件发送到一些远程的安全存储上去，比如说`Amazon`的`S3`云服务上去，在国内可以是阿里云的`ODPS`分布式存储上，以预定好的备份策略来定期备份`redis`中的数据
  - （2）`RDB`对`redis`对外提供的读写服务，影响非常小，可以让`redis`保持高性能，因为`redis`主进程只需要`fork`一个子进程，让子进程执行磁盘`IO`操作来进行`RDB`持久化即可
  - （3）相对于`AOF`持久化机制来说，直接基于`RDB`数据文件来重启和恢复`redis`进程，更加快速

- **缺点**：

  - 1）如果想要在`redis`故障时，尽可能少的丢失数据，那么`RDB`没有`AOF`好。一般来说，`RDB`数据快照文件，都是每隔5分钟，或者更长时间生成一次，这个时候就得接受一旦`redis`进程宕机，那么会丢失最近5分钟的数据
  - （2）`RDB`每次在`fork`子进程来执行`RDB`快照数据文件生成的时候，如果数据文件特别大，可能会导致对客户端提供的服务暂停数毫秒，或者甚至数秒

> AOF

- **优点**：

- - （1）`AOF`可以更好的保护数据不丢失，一般`AOF`会每隔1秒，通过一个后台线程执行一次`fsync`操作，最多丢失1秒钟的数据
  - （2）`AOF`日志文件以`append-only`模式写入，所以没有任何磁盘寻址的开销，写入性能非常高，而且文件不容易破损，即使文件尾部破损，也很容易修复
  - （3）`AOF`日志文件即使过大的时候，出现后台重写操作，也不会影响客户端的读写。因为在`rewrite log`的时候，会对其中的指导进行压缩，创建出一份需要恢复数据的最小日志出来。再创建新日志文件的时候，老的日志文件还是照常写入。当新的`merge`后的日志文件`ready`的时候，再交换新老日志文件即可。
  - （4）`AOF`日志文件的命令通过非常可读的方式进行记录，这个特性非常适合做灾难性的误删除的紧急恢复。比如某人不小心用`flushall`命令清空了所有数据，只要这个时候后台`rewrite`还没有发生，那么就可以立即拷贝`AOF`文件，将最后一条`flushall`命令给删了，然后再将该`AOF`文件放回去，就可以通过恢复机制，自动恢复所有数据

- **缺点**：

- - （1）对于同一份数据来说，`AOF`日志文件通常比`RDB`数据快照文件更大
  - （2）`AOF`开启后，支持的写`QPS`会比`RDB`支持的写`QPS`低，因为`AOF`一般会配置成每秒`fsync`一次日志文件，当然，每秒一次`fsync`，性能也还是很高的
  - （3）以前`AOF`发生过bug，就是通过`AOF`记录的日志，进行数据恢复的时候，没有恢复一模一样的数据出来。所以说，类似`AOF`这种较为复杂的基于命令日志`/merge/`回放的方式，比基于`RDB`每次持久化一份完整的数据快照文件的方式，更加脆弱一些，容易有bug。不过`AOF`就是为了避免`rewrite`过程导致的bug，因此每次`rewrite`并不是基于旧的指令日志进行merge的，而是基于当时内存中的数据进行指令的重新构建，这样健壮性会好很多。

- 



#### 8.Redis 常见性能问题和解决方案有哪些?

Redis 常见的性能问题主要是开启持久化功能的情况下引起的，比如 RDB 持久化对 CPU 资源的占用，如果这期间写请求很多还触发了 rehash 扩容操作，由于 Copy-on-write 机制，还会造成大量的内存页拷贝，这就会造成 Redis 性能降低。建议不要开启 RDB 或者主节点不开启，主从复制触发的 RDB 无法避免但可以尽量在写请求少的时候触发主从复制，不要让主节点挂载太多从节点，不要在一台机器上部署多个 redis 实例。

RDB 期间，写命令会存在复制积压缓冲区，如果缓冲区不够用（大量写请求），就会陷入一直 BGSAVE 的死循环，这种情况需要调整复制积压缓冲区的大小。

AOF 过于频繁（每条命令都保存）也会影响性能，一般设置 1 s 一次；AOF 文件过大还会影响 master 重启恢复的速度；AOF 重写对 CPU 和内存的占用也很大，也会影响性能。

总之 master 节点不建议开启持久化功能，一般从节点开启 AOF 每秒一次就行，从节点不要太多，避免复制风暴（多台从节点同时复制占用资源），最后就是网速问题，主从节点最好部署在同一局域网。

#### 9.Redis 为什么会读到过期数据？

主要是由 Redis 的删除策略导致：

- **惰性删除**：master 节点每次读取命令时都会检查键是否超时，如果超时则执行 del 命令删除键对象，之后异步把 del 命令发送给 slave 节点，这样可以保证数据复制的一致性，**slave 节点是永远不会主动去删除超时数据**的。
- **定时删除**：Redis 的 master 节点在内部定时任务，会循环采样一定数量的键，当发现采样的键过期时，会执行 del 命令，之后再同步给 slave节点，**采样速度跟不上数据过期速度**。
- **主动删除**：当前已用内存**超过 maxMemory 限定时，才会触发主动清理策略**。主动删除的前提是设置了 maxMemory 的值。

**根本原因就是 slave 节点不能主动 delete 过期 key。**

> Redis 3.2 以经解决了 Redis 删除策略导致的过期数据（slave 节点读取数据之前会检查过期时间来决定是否返回数据）。



#### 10.为什么 Redis 需要把所有数据放到内存中？

避免磁盘 IO，提升读写性能

#### 11.Redis 的同步机制了解么？



#### 12.Pipeline 有什么好处，为什么要用 Pipeline？

减少网络开销，一条一条命令与 redis 进行交互和多条命令一次性提交给 redis，肯定是后者更快。

#### 13.是否使用过 Redis 集群，集群的原理是什么？



#### 14.Redis 集群方案什么情况下会导致整个集群不可用？

#### 15.Redis 支持的 Java 客户端都有哪些？官方推荐用哪个？

#### 16.Jedis 与 Redisson 对比有什么优缺点？

#### 17.Redis 如何设置密码及验证密码？

#### 18.说说 Redis 哈希槽的概念？

#### 19.Redis 集群的主从复制模型是怎样的？

#### 20.Redis 集群会有写操作丢失吗？为什么？

#### 21.Redis 集群之间是如何复制的？

#### 22.Redis 集群最大节点个数是多少？

#### 23.Redis 集群如何选择数据库？

#### 24.怎么测试 Redis 的连通性？

#### 25.怎么理解 Redis 事务？

#### 26.Redis 事务相关的命令有哪几个？

#### 27.Redis key 的过期时间和永久有效分别怎么设置？

#### 28.Redis 如何做内存优化？

#### 29.Redis 回收进程如何工作的？

#### 30.都有哪些办法可以降低 Redis 的内存使用情况呢？

#### 31.Redis 的内存用完了会发生什么？

#### 32.一个 Redis 实例最多能存放多少的 keys？List、Set、Sorted Set他们最多能存放多少元素？

#### 33.MySQL 里有 2000w 数据，Redis 中只存 20w 的数据，如何保证Redis 中的数据都是热点数据？

#### 34.Redis 最适合的场景是什么？

#### 35.假如 Redis 里面有 1 亿个 key，其中有 10w 个 key 是以某个固定的已知的前缀开头的，如果将它们全部找出来？

#### 36.如果有大量的 key 需要设置同一时间过期，一般需要注意什么？

#### 37.使用过 Redis 做异步队列么，你是怎么用的？

#### 38.使用过 Redis 分布式锁么，它是什么回事？

#### 39.如何预防缓存穿透与雪崩？

- **缓存穿透**
  1. 当查询数据库为空的时候，把这个 key 缓存起来
  2. 使用布隆过滤器

- **缓存雪崩**

> 在某一时刻，大量缓存同时失效导致所有请求都去查询数据库，导致数据库压力过大而挂掉。

<font color="#398BDE">解决方案</font>

1. 缓存高可用，比如 Redis 集群
2. 缓存失效时间要设计好。不同的数据有不同的有效期，尽量保证不要在同一时刻失效，统一规划有效期，让失效时间分布均匀即可。
3. 定时更新热门数据，以刷新缓存，从而避免自动失效。
4. 服务限流和接口限流。如果服务和接口都有限流机制，就算缓存全部失效了，但是请求的总量是有限制的，可以在承受范围之类，这样短时间内系统响应慢点，但不至于挂掉，影响整个系统。
5. 从数据库获取缓存需要的数据时加锁控制，本地锁或分布式锁都可以。当所有请求都不能命中缓存，这时候就要去数据库查询，如果同时并发的量大，也会导致雪崩的发生，可以在对数据库查询的地方进行加锁控制，不要让所有请求都过去，这样可以保证存储服务不挂掉。

#### 40. Redis 可能会导致的问题？

- 缓存和数据库双写一致性问题
  - 通过代码保证 redis 和关系型数据库的数据一致性是不可靠的
  - 可以使用 canal 监控数据库的 binlog 将数据的变化实时同步到 redis

- 缓存击穿：如果某一个热点数据的缓存过期了，那么当大量用户同时访问这个热点数据时，就会导致数据库在缓存过期的瞬间压力突然增大；
- 缓存雪崩：如果大量数据的缓存同时失效（可能是给大量缓存设置了相同的过期时间，也可能是缓存服务器出现故障等），那么全部的后台请求将直接奔向数据库，从而导致数据库压力过大；
- 缓存穿透：一般而言，我们会将那些频繁查询的数据放入缓存，并不会缓存毫无意义的数据。但这也给一些不怀好意的人带来了可乘之机：如果有人恶意大量查询一些不存在的商品，那么这些查询请求就会绕过缓存而直达数据库，因此也会给数据库带来很大压力。

> 不难发现，缓存击穿、缓存雪崩和缓存穿透都是由于某种情况下的“缓存失效”所导致的。三者也都有各自的解决方案，举例如下：

- 避免缓存击穿：通过一个线程实时监控热点数据的过期时间，如果发现某个缓存快要过期了，就开启一个异步线程去更新缓存，从而重置过期时间。或者也可以简单一点：在秒杀开始前，手工的设置热点数据在秒杀期间不会过期。；
- 避免缓存雪崩：搭建缓存集群（如 Redis 集群），并合理的分配缓存的过期时间；
- 避免缓存穿透：对于不存在的商品，也将其以value="“的形式进行缓存（例如， key =“不存在的商品”, value =”"）。这样一来，当以后再次查询“不存在的商品”时，也能迅速的从缓存中查到结果(结果就是"")。此外，为了防止大量无效数据长时间占用缓存容量，可以将这些无意义缓存的过期时间设置的短一些。



#### 41. Reids 为什么快、高并发的原因？

- 纯内存数据库
- Redis 采用了单线程的模型，保证了每个操作的原子性，也减少了线程的上下文切换和竞争。
- 另外，数据结构也帮了不少忙，Redis 全程使用 hash 结构，读取速度快，还有一些特殊的数据结构，对数据存储进行了优化，如压缩表，对短数据进行压缩存储，再如，跳表，使用有序的数据结构加快读取的速度。
- 还有一点，Redis 采用自己实现的事件分离器，效率比较高，内部采用非阻塞的执行方式，吞吐能力比较大。

- 采用了非阻塞 I/O 多路复用机制，使用了单线程来轮询描述符，减少了线程切换时上下文的切换和竞争。



#### 42. Redis 做分布式锁的时候有需要注意的问题？

一定要保证自己加的锁，自己才能释放。碰到过一种场景，线程A 加锁后执行太久（可能是涉及到 RPC 调用，超时了），锁超时释放了，线程B 就获得锁了，这时线程 A 终于执行到释放锁的逻辑，把线程B 的锁释放了，线程C 获得锁，可能又被线程B 释放，就这样恶性循环。这种情况分布式锁的作用就失效了，无法保证顺序执行。

锁超时释放，要么是过期时间不合理，要么是网络问题，要么是调用其他服务不稳定引起，应该尽可能缩小锁的范围。

因为锁超时释放而获得的锁可以添加额外的逻辑，比如转成关系型数据库加锁，或者中断原本持有锁的线程，锁超时释放了，业务逻辑也按失败处理。

想要中断原本持有锁的线程就要使用 RPC 调用，分布式锁可以用 hash 来实现，key 存放 `ip + 线程ID`，value 存放过期时间，加锁前 java 代码也要用 Map 保存 Thread 对象，key 为线程ID，这样就能通过线程ID 获取线程对象进行 interrupt 中断操作了。


#### 43. 如果是 Redis 是单点部署的，会带来什么问题？

宕机直接导致所有访问 redis 的请求失败

#### 44. 那你准备怎么解决单点问题呢？

主从 + Sentinel、Cluster

#### 45. 集群模式下，比如主从模式，有没有什么问题呢？

使用分布式锁时，当获取锁后，master 还未将命令同步到 slave，新的 master 被选举出来，分布式锁又可以获取了，这就出现了一个锁同一时刻被两个线程持有。


#### 46. 你知道 Redis 是怎么解决集群模式也不靠谱的问题的吗？


#### 47. 那你简单的介绍一下 Redlock 吧？


#### 48. 你觉得 Redlock 有什么问题呢？

#### 49. 加入设置参数 maxmemory 为 100M，当数据超过 100M 时，Redis 会怎样处理？

当内存满了 100M 的时候，如果还接收到 set 命令， redis 将先尝试剔除设置过 expire 信息的 key，而不管该 key 的过期时间还没有到达，根据淘汰算法进行删除。

如果带有 expire 信息的 key 都删光了，那么将返回错误。这样， redis 将不再接收写请求，只接收 get 请求。

#### 50. 无法从连接池中获取连接（超时）可能的原因

- 慢查询阻塞：池子连接都被 hang 住。
- 资源参数不合理：例如 QPS 高，池子小。
- 连接泄露（没有close()）：也就是没有归还连接，可以用 client list、netstat 观察连接的一个增长情况，最重要的是 `try…catch…finally`。

#### 51. 为什么 bgsave 和 aof 重写的时候 rehash 的负载因子变成 5 了

因为 bgsave 和 aof 重写是 fork 一个子进程去做的，内核把父进程中所有内存页的权限都设置为 read-only，当父进程需要修改数据时需要拷贝一份数据页，在 bgsave 和 aof 重写期间 rehash 可能造成大量的内存拷贝，性能低下，所以这个期间触发 rehash 的条件从【负载因子 = 1】变成了 【负载因子 = 5】。

#### 52. Reids 服务器操作系统基本信息告警，你认为是那些原因？

- 从节点太多造成复制风暴；

- 全量同步过程未结束，主节点接收大量写请求，复制积压缓冲区满了，触发重新同步；

- 网络较差，主从断开重连后，又要重新同步（Redis 2.8 以前只能全量同步，不支持增量）；

- BigKey 造成网络 IO 超时。

#### 53. redis 可以用在哪些业务上？

- 缓存
- 分布式锁
- 简易的分布式消息队列（Lists 或 Streams）
- 简易的订阅通知（Pub/Sub)
- 延时通知（键过期事件通知）
- 附近的人（GEO）
- 用户签到

#### 54. Redis 有什么缺点？

- 缓存和数据库双写一致性问题
- 缓存雪崩问题
- 缓存穿透问题
- 缓存的并发竞争问题

#### 55. 使用 Redis 有哪些好处

- 速度快，因为数据存在内存中，类似于`HashMap`，`HashMap`的优势就是查找和操作的时间复杂度都是O(1)
- 支持丰富数据类型，支持`string`，`list`，`set`，`sorted` `set`，`hash`
- 支持事务，操作都是原子性，所谓的原子性就是对数据的更改要么全部执行，要么全部不执行
- 丰富的特性：可用于缓存，消息，按key设置过期时间，过期后将会自动删除。

#### 56. Redis 提供了几种数据淘汰策略？该怎么选择？

默认策略是不清除，内存满了就不再接收写请求，直接返回错误。另外还有 3 种策略：随机清除、LRU 和 LFU，这 3 种策略分别可以选择是针对所有 key 还是只针对有过期时间的 key。

- LRU 是最近最少使用，Redis 是随机采样，默认配置是每次取 5 个 key，进行判别
- LFU 是最少使用

最后还有一种，从设置了过期时间的 key 中挑最快过期的进行淘汰。

如果所有 key 的访问频率都差不多使用随机淘汰就好，如果有部分数据访问频率不高就使用 lru。

#### 57. Redis 为什么之前一直不使用多线程，6.0 为什么又使用了？

使用 Redis 的瓶颈主要是内存和网络，CPU 不会成为瓶颈，使用多线程会增加线程切换的开销、还会带来一些并发读写的问题、增加了复杂度。

对于 80% 的公司来说，8w 到 10w 的 QPS 已经足够了，不过随着业务场景越来越复杂，有些公司动不动就上亿的交易量，因此需要更大的 QPS，采用分布式的 Redis 解决方案，增加了运维成本、服务器投入成本。所以 6.0 版本为了提高网络 IO 性能使用了多线程来处理网络数据的读写和协议解析，执行命令仍然是单线程的，而且默认是禁用多线程的，需要将 `io-threads-do-reads` 参数设置为 yes 才会启用多线程。

官方推荐至少要 4 核的机器才开启多线程，线程数的设置不能高于 cpu 核心数，而且超过 8 个基本上没有意义。

#### 58. Redis6.0多线程的实现机制？

主线程获取可读的 socket 会先放入一个等待队列，等待队列满了再交给一个 IO 线程组处理，读取 socket 中的数据和协议解析由 IO 线程组完成，这里是并发执行的，提升了 IO 效率，期间主线程阻塞，IO 线程组处理完后，主线程才开始执行所有请求命令。

#### 59. Redis 如何做到高可用？

redis 有两种持久化方式 AOF 和 RDB 能够尽量不丢失数据，Redis 还支持主从、集群部署保证服务的可用性。



